---
title: "Cluster generation from (incomplete) minicensus"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: "hide"
---


```{r setup, include=FALSE, echo = FALSE}
# Basic knitr options
library(knitr)
opts_chunk$set(comment = NA, 
               # echo = FALSE, 
               warning = FALSE, 
               message = FALSE, 
               error = TRUE, 
               cache = FALSE,
               fig.width = 9.64,
               fig.height = 5.9,
               fig.path = 'figures/')
options(scipen=999)
```

```{r}
## Load libraries
library(bohemia)
library(ggplot2)
library(lubridate)
library(dplyr)
library(ggplot2)
library(sp)
library(raster)
library(ggthemes)
library(sf)
library(RColorBrewer)
library(readr)
library(tidyr)
library(leaflet)
library(rgeos)
# options(scipen = '999')
theme_set(databrew::theme_simple())
```


```{r}
extract_ll <- function(x){
  lngs <- lats <- c()
  for(i in 1:length(x)){
    y <- x[i]
    lat <- unlist(lapply(strsplit(y[1], ' '), function(z){z[1]}))
    lng <- unlist(lapply(strsplit(y[1], ' '), function(z){z[2]}))
    lngs[i] <- lng; lats[i] <- lat
  }
  
  lng <- as.numeric(lngs); lat <- as.numeric(lats)
  return(tibble(lng = lng, lat = lat))
}

if('data.RData' %in% dir()){
  load('data.RData')
} else {
  pd_moz <- load_odk_data(the_country = 'Mozambique',
                    credentials_path = '../../../credentials/credentials.yaml',
                    users_path = '../../../credentials/users.yaml',
                    efficient = FALSE)
  pd_tza <- load_odk_data(the_country = 'Tanzania',
                    credentials_path = '../../../credentials/credentials.yaml',
                    users_path = '../../../credentials/users.yaml',
                      efficient = FALSE)
  is_local <- FALSE
  library(DBI)
  library(RPostgres)
  save(pd_moz,
       pd_tza,
       file = 'data.RData')
}

minicensus_main <- bind_rows(
  pd_moz$minicensus_main,
  pd_tza$minicensus_main
)
minicensus_people <- bind_rows(
  pd_moz$minicensus_people,
  pd_tza$minicensus_people
)
na_to_zero <- function(x){ifelse(is.na(x), 0, x)}
gps <- bohemia::gps

df_adjust <- function(df){
  df %>%
    mutate(n_households = ifelse(df$iso == 'TZA', n_households * 1,
                                 ifelse(df$iso == 'MOZ', n_households * 0.55, 
                                        NA)))
}

# source('global.R')
source('try_clusters_hh_level.R')

# Define the number of clusters required of each type
n_required <- 49

# Get age and household details
ages <- 
  bind_rows(
    pd_moz$minicensus_people %>% mutate(country = 'Mozambique'),
    pd_tza$minicensus_people %>% mutate(country = 'Tanzania')
  ) %>%
  mutate(days_old = Sys.Date() - dob) %>%
  mutate(years_old = days_old / 365.25) %>%
  mutate(is_child  = ifelse(country == 'Mozambique',
                            years_old >= 0 & years_old < 5,
                            years_old >= 5 & years_old < 15)) %>%
  group_by(country) %>%
  summarise(children = length(which(is_child)),
            people = n()) %>%
  ungroup %>%
  mutate(percent_children = round(children / people * 100, digits = 2))

hh <- bind_rows(
  pd_moz$minicensus_main %>% mutate(country = 'Mozambique'),
  pd_tza$minicensus_main %>% mutate(country = 'Tanzania')
) %>%
  group_by(country) %>%
  summarise(avg_size = mean(hh_size))
```

```{r}
# Create a df based on minicensus
left <- minicensus_people %>%
  left_join(minicensus_main %>% dplyr::select(instance_id,
                                              country = hh_country)) %>%
  mutate(years_old = (Sys.Date() - dob)/ 365.25) %>%
  mutate(under5 = years_old >= 0 & years_old <= 5) %>%
   mutate(is_child  = ifelse(country == 'Mozambique',
                            years_old >= 0 & years_old <= 5,
                            years_old >= 0 & years_old <= 15)) %>%
  mutate(is_boy = is_child & gender == 'male') %>%
  mutate(is_girl = is_child & gender == 'female') %>%
  group_by(country, instance_id) %>%
  summarise(n_members = n(),
            under5s = length(which(under5)),
            reproductive = length(which(gender == 'female' & years_old >=13 & years_old <= 49)),
            n_females = length(which(gender == 'female')),
            n_males = length(which(gender == 'male')),
            n_boys = length(which(is_boy)),
            n_girls = length(which(is_girl)),
            n_children = length(which(is_child)))
df_full <- df <-
  left_join(left,
            minicensus_main %>% dplyr::select(instance_id,
                                              cows_1_year_plus = hh_n_cows_greater_than_1_year,
                                              cows_babies = hh_n_cows_less_than_1_year,
                                              pigs_6_weeks_plus = hh_n_pigs_greater_than_6_weeks,
                                              pigs_babies = hh_n_pigs_less_than_6_weeks,
                                              # country = hh_country,
                                              code = hh_hamlet_code,
                                              n_people = hh_size,
                                              location = hh_geo_location)) 
# Function for extracting lng and lat from a odk geocode object
extract_ll <- function(x){
  lngs <- lats <- c()
  for(i in 1:length(x)){
    y <- x[i]
    lat <- unlist(lapply(strsplit(y[1], ' '), function(z){z[1]}))
    lng <- unlist(lapply(strsplit(y[1], ' '), function(z){z[2]}))
    lngs[i] <- lng; lats[i] <- lat
  }
  
  lng <- as.numeric(lngs); lat <- as.numeric(lats)
  return(tibble(lng = lng, lat = lat))
}
locs <- extract_ll(df$location)
df$lng <- df$x <- locs$lng; df$lat <- df$y <- locs$lat
# df$code <- df$hh_hamlet_code
df <- left_join(df, bohemia::locations %>% 
                  dplyr::distinct(code, .keep_all = TRUE) %>%
                  dplyr::select(code, clinical_trial))

df <- df %>% filter(lat < -3)
df <- df %>%
  filter((lat < -16 & country == 'Mozambique') |
           (lat > -12 & country == 'Tanzania')
  )
library(sp)


# Aggregate df
df_agg <- df %>%
  group_by(code) %>%
  summarise(n_humans = sum(n_members),
            n_females = sum(n_females),
            n_males = sum(n_males),
            n_boys = sum(n_boys),
            n_girls = sum(n_girls),
            n_households = n(),
            n_children = sum(n_children),
            clinical_trial = dplyr::first(clinical_trial),
            country = dplyr::first(country),
            lng = mean(lng),
            lat = mean(lat),
            cows_1_year_plus = sum(cows_1_year_plus, na.rm = TRUE),
            cows_babies = sum(cows_babies, na.rm = TRUE),
            pigs_6_weeks_plus = sum(pigs_6_weeks_plus, na.rm = TRUE),
            pigs_babies = sum(pigs_babies, na.rm = TRUE))
df_agg <- df_agg %>% arrange(code)


# Read in cluster difficulty access scores (sent from Eldo)
difficulty <- read_csv('Mopeia.Hamlets_Accessibility_Scores.08.03.2021.csv')
difficulty <- difficulty %>% dplyr::select(code, difficulty = Accessibility_Scores)
difficulty$difficulty_value <- 
  ifelse(difficulty$difficulty == 'Easy', 1,
         ifelse(difficulty$difficulty == 'Normal', 2,
                ifelse(difficulty$difficulty == 'Hard', 3,
                       ifelse(difficulty$difficulty == 'Very Hard', 4,
                              NA))))
# Read in difficulty sent by Imani on March 22 2021
difficulty_tza <- read_csv('Bohemia hamlets_Accessibility.csv') %>%
  dplyr::select(code = hamlet_code,
                difficulty = Accessibility) %>%
  mutate(difficulty_value = 
             ifelse(difficulty == 'Easy', 1,
         ifelse(difficulty == 'Normal', 2,
                ifelse(difficulty == 'Hard', 3,
                       ifelse(difficulty == 'Very Hard', 4,
                              NA)))))
difficulty_tza <- difficulty_tza %>% filter(!duplicated(code))
difficulty <- bind_rows(difficulty, difficulty_tza)
difficulty <- difficulty %>% filter(!is.na(difficulty_value))
df_agg <- left_join(df_agg, difficulty)
df_agg <- df_agg %>% filter(!duplicated(code))
df_agg <- df_agg %>% filter(!is.na(difficulty_value))



# Get the data grouped by codes
codes <- sort(unique(df_agg$code))
locations_list <- list()
locations_list_ll <- list()
for(i in 1:length(codes)){
  # message('INDEX ', i)
  this_code <- codes[i]
  this_data <- df %>% filter(code == this_code) %>% mutate(x = lng, y = lat)
  coordinates(this_data) <- ~x+y
  proj4string(this_data) <- proj4string(bohemia::mop2)
  # CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
  ss <- spTransform(this_data, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
  # Get distances
  # dd <- rgeos::gDistance(ss, byid = TRUE)
  # Throw out anything more than 3k from centroid?
  centroid <- apply(coordinates(ss), 2, median)
  centroid <- data.frame(t(as.data.frame(centroid)))
  coordinates(centroid) <- ~x+y
  proj4string(centroid) <- proj4string(ss)
  distance_from_centroid <- rgeos::gDistance(ss, centroid, byid = TRUE)
  remove_these <- which(distance_from_centroid > 3000)
  if(length(remove_these) > 0){
    message('Removing ', length(remove_these), ' of ', nrow(ss), ' due to weird distances.')
    this_data <- this_data[!(1:nrow(this_data)) %in% remove_these,]
    ss <- ss[!(1:nrow(ss)) %in% remove_these,]
  } else {
    message('No removals for hamlet of ', nrow(ss))
  }
  locations_list_ll[[i]] <- this_data
  locations_list[[i]] <- ss
}
names(locations_list) <- names(locations_list_ll) <- codes
locations_df <- do.call('rbind', locations_list)
df <- locations_df@data
df_sp <- df
coordinates(df_sp) <- ~lng+lat
proj4string(df_sp) <- proj4string(bohemia::mop2)
df_proj <- spTransform(df_sp,   CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
)


# Remake the aggregated dataframe, overwriting df
df <- df %>%
  ungroup %>%
  group_by(code) %>%
  summarise(n_humans = sum(n_members),
            under5s = sum(under5s),
            n_reproductive = sum(reproductive),
            n_females = sum(n_females),
            n_males = sum(n_males),
            n_boys = sum(n_boys),
            n_girls = sum(n_girls),
            n_households = n(),
            n_children = sum(n_children),
            clinical_trial = dplyr::first(clinical_trial),
            country = dplyr::first(country),
            lng = mean(lng),
            lat = mean(lat),
            cows_1_year_plus = sum(cows_1_year_plus, na.rm = TRUE),
            cows_babies = sum(cows_babies, na.rm = TRUE),
            pigs_6_weeks_plus = sum(pigs_6_weeks_plus, na.rm = TRUE),
            pigs_babies = sum(pigs_babies, na.rm = TRUE))
df <- df %>% arrange(code)


# Combine with difficulty
df <- left_join(df, difficulty)
```

## Jelly beans of 200 adults

```{r}
# 20210329 22:37 Clusters. Carlos
# Create clusters of adults: size 200 
# Start in any random point
# Randomly assign to three statuses A-B-C
# If next cluster has the same status as previous one, then start immediately next to it
# If next cluster has a status different than previous one, then start at any random point 1km away from the border of any cluster
# 
# Identify the clusters that contain at least 30 children 
# 
# From the above, randomly select 147
# 
# Collapse the borders of neighbouring clusters with same status
# 
# Identify the core of each cluster, defined as: the area at least 1 km away from all borders of the cluster (may be as low as 0 km2)
# 
# Calculate the number of children in the core for every cluster
# 
# Calculate the min and max distance from cluster core to cluster border for every cluster
# 
# This approach:
# 
# Starts with an affordable unit (200 adults) and fixes the costs
# Leverages random equal status to create efficiency
# Automatically creates a 1km buffer between discordant clusters
# Allows for clusters with varying numbers of children
# Allows for children to be distributed either on a small core or throughout the cluster
# Makes the distance between a child and the next discordant household at least 1 km
# Leverages neighbors with same status to create larger cores of children

buffer_distance <- 0.01
households <- df_sp[df_sp@data$code %in% df$code[df$country == 'Mozambique'],]# %>% filter(country == 'Mozambique')
households_projected <- spTransform(households, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
# Get distances between all households
if(!'ad.RData' %in% dir()){
  all_distances <- gDistance(households_projected, byid = T)
  save(all_distances, file = 'ad.RData')
} else {
  load('ad.RData')
}
```


```{r}
# go through each individual household, defining cores along the way
households <- df_sp[df_sp@data$code %in% df$code[df$country == 'Mozambique'],]# %>% filter(country == 'Mozambique')
households_projected <- spTransform(households, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
households_projected@data$id <- 1:nrow(households_projected)
households_projected$status <- 'available'
households_projected$cluster <- households_projected$cc <- households_projected$assignment_group <- NA
households_projected@data$n_adults <- households_projected@data$n_people - households_projected@data$n_children

households_projected@data$distance_id <- 1:nrow(households_projected)


# Define a function for creating a core given a point and a set of eligible households

create_core <- function(pt, eligibles, n_clusters = 1){
  # Get distance from pt to eligibles
  distances <- spDists(pt, eligibles)
  distances <- distances[1,]
  
  keep <- order(distances)
  enough <- FALSE
  counter <- 0
  cc_vec <- cluster_number_vec <- c()
  cluster_number <- 1
  while(!enough){
    # message('---working on cluster ', cluster_number)
    counter <- counter + 1

    keep_only <- keep[1:counter]
    core <- eligibles[keep_only,]
    n_adults <- sum(core@data$n_adults)
    cc_vec[counter] <- n_adults
    cluster_number_vec[counter] <- cluster_number
    xdf <- tibble(cc = cc_vec,
                  cluster = cluster_number_vec) %>%
      mutate(n_c = cc - dplyr::lag(cc, 1)) %>%
      mutate(n_c = ifelse(is.na(n_c), cc, n_c))
    xdf <- xdf %>% filter(cluster == cluster_number)
    # see if we've just passed the threshold for this cluster
    just_passed <- FALSE
    if(nrow(xdf) > 1){
        just_passed <- sum(xdf$n_c) >= 200
        if(just_passed){
          cluster_number <- cluster_number + 1
        }
    }
    enough <- cluster_number > n_clusters #n_children >= (35*n_clusters)
  }
  cc_out <- cluster_number_vec
  core@data$cc <- cc_out
  message('---Successfully created a core area of ', n_adults)
  return(core)
}


# Define a random starting point
set.seed(1)
library(rangemap)
done <- FALSE
cluster_counter <- 0
buffers_list <- cores_list <- cores_poly_list <- list()
palette <- rainbow(3)

# Create an assignment vector
assignment_vector <- c(rep(1, 49), rep(2, 49), rep(3, 49))
assignment_vector <- sample(assignment_vector, length(assignment_vector))
# Add to it in case we have more than 3*48 clusters
part2 <- sample(1:3, size = 1000000 - length(assignment_vector), replace = TRUE)
assignment_vector <- c(assignment_vector, part2) # this is now unnecessarily long, but at least has perfect uniform distribution for the first 144 elements, which is needed

# Based on assignment vector, get a vector of grouped assignments
assignment_groups <- c(1)
counter <- 1
for(i in 2:length(assignment_vector)){
  if(!assignment_vector[i] == assignment_vector[i-1]){
    counter <- counter + 1
  }
  assignment_groups[i] <- counter
}
unique_assignment_groups <- sort(unique(assignment_groups))
ag_df <- tibble(assignment = assignment_vector,
                assignment_group = assignment_groups)
ag_counter <- 0
cols <- palette[ag_df$assignment]


while(!done){
  ag_counter <- ag_counter + 1  
  this_assignment <- ag_df$assignment[ag_df$assignment_group == ag_counter][1]

  # Get the n rows for the assignment group
  nr <- ag_df %>% filter(assignment_group == ag_counter) %>% nrow()
  # Get number of adults
  n <- nr * 200
  # cluster_counter <- cluster_counter + 1
  # this_assignment <- assignment_vector[cluster_counter]
  message('Working on assignment group: ', ag_counter, '. ', nr, ' clusters')
  # elbs <- households_projected[households_projected@data$status == 'available',]
  elbs <- households_projected[households_projected@data$status != 'core',]
  eligible_ids <- elbs@data$distance_id
  
  if(ag_counter > 1){
      # Eligibles have to be at least 2km from the edge of the already assigned areas
     # elbs_distances <- gDistance(all_buffers, elbs, byid = T) # get distance from all_buffers
    # We want to get those which are FAR from households already assigned to ANOTHER assignment status
    previous <- households_projected
    previous@data <- left_join(previous@data, ag_df %>% dplyr::distinct(assignment_group, assignment))
    # previous_nas <- previous[is.na(previous@data$assignment),] 
    as_close_to_here_as_possible <- previous_not_nas <- previous[!is.na(previous@data$assignment),]
    previous_not_nas <- previous_not_nas[previous_not_nas@data$assignment != this_assignment,]
    stay_away_from_these <- previous_not_nas
  stay_away_from_these <- hull_polygon(stay_away_from_these, hull_type = 'concave')#gConvexHull(core)
    stay_away_from_these <- SpatialPolygonsDataFrame(
    Sr = stay_away_from_these,
    data = data.frame(x = 1),
    match.ID = FALSE
  )
    stay_away_from_these_ids <- stay_away_from_these@data$distance_id
    
    # Keep ONLY households which are sufficiently far from the stay-away households
    these_distances <- all_distances[eligible_ids, stay_away_from_these_ids]
    elbs_distances <- apply(these_distances, 1, min)
    keep_elbs <- elbs_distances >= (buffer_distance*2) # multiply by 2, since the distance is not including their buffer
    elbs <- elbs[keep_elbs,]

    # Now we have only eligible points. But we want to start the next one as close as possible to
    # the already assigned areas. THIS CAUSES ISSUES. COMMENTING OUT
    # eligible_ids <- elbs@data$distance_id
    # as_close_to_here_as_possible_ids <- as_close_to_here_as_possible@data$distance_id
    # these_distances <- all_distances[eligible_ids, as_close_to_here_as_possible_ids]
    # elbs_distances <- apply(these_distances, 1, min)
    # random_index <- which.min(elbs_distances)[1]
    random_index <- sample(1:nrow(elbs), 1)
    
  } else {
    random_index <- sample(1:nrow(elbs), 1)
  }

  this_hh <- elbs[random_index,]
  # Create core
  core <- create_core(pt = this_hh, eligibles = elbs, n_clusters = nr)
  core@data %>%
    group_by(cc) %>%
    summarise(kids = sum(n_children))
  # Create convex hull
  suppressMessages({
    hull <- hull_polygon(core, hull_type = 'concave')#gConvexHull(core)
    hull <- SpatialPolygonsDataFrame(
    Sr = hull,
    data = data.frame(assignment_group = ag_counter,
                      assignment = this_assignment),
    match.ID = FALSE
  )
  })
  # # Create buffer 
  # buffer <- gBuffer(core, width = buffer_distance)
  # buffer <- SpatialPolygonsDataFrame(
  #   Sr = buffer,
  #   data = data.frame(assignment_group = ag_counter,
  #                     assignment = this_assignment),
  #   match.ID = FALSE
  # )
  # # Identify the households in the buffer
  # hh_in_buffer_index <- over(households_projected, polygons(buffer))
  # hh_in_buffer_index <- which(!is.na(hh_in_buffer_index))
  # hh_in_buffer <- households_projected[hh_in_buffer_index,]
  # # Get the ids of those in the buffer
  # ids_in_buffer <- hh_in_buffer@data$id
  # Get the ids of those in core
  ids_in_core <- core@data$id
  # ids_in_buffer <- ids_in_buffer[!ids_in_buffer %in% ids_in_core]
  message('------', length(ids_in_core), ' households in core.')
  message('------', sum(core@data$n_children), ' children in core.')
  # message('------', length(ids_in_buffer), ' households in buffer')
  # Write to the master dataframe
  # households_projected@data$status[households_projected@data$id %in% ids_in_buffer] <- 'buffer'
  # households_projected@data$status[households_projected@data$id %in% ids_in_core] <- 'core'
  # households_projected@data$assignment_group[households_projected@data$id %in% ids_in_buffer] <- ag_counter
  # households_projected@data$assignment_group[households_projected@data$id %in% ids_in_core] <- ag_counter
  core@data$assignment_group <- ag_counter
  core@data$status <- 'core'
  # Get the cc number
  non_core <- households_projected[!households_projected@data$id %in% ids_in_core,]
  households_projected <- rbind(core, non_core)
  # # Save polygons
  # buffers_list[[ag_counter]] <- buffer
  # cores_list[[ag_counter]] <- core
  cores_poly_list[[ag_counter]] <- hull
  # 
  # 
  # # Create an evolving map of buffers
  # all_buffers <- do.call('rbind', buffers_list)
  # all_buffers <- spTransform(all_buffers, proj4string(households_projected))
  all_cores <- do.call('rbind', cores_poly_list)
  all_cores <- spTransform(all_cores, proj4string(households_projected))

  sub_ag_df <- ag_df %>% filter(assignment_group <= ag_counter)
  already_assigned <- households_projected[households_projected@data$status == 'core',]
  already_assigned@data <- left_join(already_assigned@data, ag_df %>% dplyr::distinct(assignment, assignment_group))
  # plot(households_projected, pch = '.', cex = 0.5,
  #      col = adjustcolor('black', alpha.f = 0.3))
  # plot(all_cores, add = T,
  #      col = adjustcolor(cols[1:ag_counter], alpha.f = 0.3))
  plot(already_assigned, pch = '.',
         col = cols[already_assigned@data$assignment])
  plot(all_cores, add = T)
  

  title(main = paste0(ag_counter, ' assignment groups finished.\nBuffer distance: ', buffer_distance),
        sub = paste0(nrow(sub_ag_df), ' clusters done.'))
  tt <- households_projected@data %>%
    group_by(assignment_group, cc) %>%
    summarise(kids = sum(n_children))
  print(ungroup(tt))
  # print(table(households_projected@data$assignment_group[households_projected@data$status == 'core']))
  # Sys.sleep(0.35)
  # Check to see if done
  cluster_counter <- nrow(sub_ag_df)
  done <- cluster_counter >= 1000
}

# Get only those hamlets which are sufficient to have reached 147
pd <- households_projected@data %>%
  group_by(cluster) %>%
  summarise(kids = sum(n_children))

# Now, for each polygon, get the sub inner polygon with 35 or more kids. To do this, start at the centroid, and then work outwards until 35 is reached (cannot due for clusters with < 35 kids, of course)
table(households_projected@data$status)
table(households_projected@data$assignment_group)
households_projected@data <- 
  left_join(households_projected@data,
            ag_df %>%
              dplyr::distinct(assignment, assignment_group))
table(households_projected@data$assignment)

# Get number of children per 
```


# Combine first

```{r}
x <- df_sp[df_sp@data$code %in% df$code[df$country == 'Mozambique'],]# %>% filter(country == 'Mozambique')
x@data$n_adults <- x@data$n_people - x@data$n_children
x$cluster <- as.numeric(factor(as.character(x$code)))
# Get smallest adjoining
clusters <- sort(unique(x$cluster))
for(i in 1:length(clusters)){
  this_cluster <- clusters[i]
  message(this_cluster, '. ', i, ' of ', length(clusters))
  these_hh <- x[x@data$cluster == this_cluster,]
  # n_children <- sum(these_hh@data$n_children)
  n_adults <- sum(these_hh@data$n_adults)
  while(n_adults < 200){
  # while(n_children < 35){
    # message('---', n_children, ' is too low. Adding')
    message('---', n_adults, ' is too low. Adding')

    other_hh <- x[x@data$cluster != this_cluster,]
    # not enough children, add to nearby area
    distances <- spDists(x = these_hh,
                         y = other_hh)
    nearest_index <- which.min(apply(distances, 2, min))
    nearest_cluster <- other_hh@data$cluster[nearest_index]
    # Assign those to the same cluster
    x@data$cluster[x@data$cluster == nearest_cluster] <- this_cluster
    these_hh <- x[x@data$cluster %in% c(this_cluster),]
    # n_children <- sum(these_hh@data$n_children)
    n_adults <- sum(these_hh@data$n_adults)
  }
}

# Check to make sure that we have 35 or more per cluster
outcome <- x@data %>%
  group_by(cluster) %>%
  summarise(n_adults = sum(n_adults)) %>%
  arrange(n_adults)
  # summarise(n_children = sum(n_children)) %>%
  # arrange(n_children)

# Re number the clusters
x@data$cluster <- as.numeric(factor(as.character(x$cluster)))

# Sanity check (plot)
color_palette <- rainbow(length(unique(x@data$cluster)))
color_palette <- sample(color_palette, size = length(color_palette))
cols_vec <- color_palette[x@data$cluster]
leaflet() %>%
  addTiles() %>%
  addCircleMarkers(data = x,
                   weight = 1,
                   opacity = 0.6,
                   fillOpacity = 0.7,
                   fillColor = cols_vec,
                   popup = paste0(
                     'Cluster: ', x@data$cluster,
                     ' Hamlet: ', x@data$code
                   ))

# Now that we have clusters, and all clusters have >= 35 children, time to establish cores and buffers
# Define function to get a "core" based on a distribution
get_core <- function(spatial_dataframe){
  # spatial_dataframe <- x[x@data$cluster == 1,]
  # Project
  original_projection <- proj4string(spatial_dataframe)
  projected <- spTransform(spatial_dataframe, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
# Get those points which are nearest to other points
  distances <- spDists(x = spatial_dataframe)
  dd <- apply(distances, 1, mean)
  # Keep only those needed to get up to 35 children
  keep <- order(dd)#[1:35]
  enough <- FALSE
  counter <- 0
  while(!enough){
    counter <- counter + 1
    # message(counter)
    keep_only <- keep[1:counter]
    core <- projected[keep_only,]
    n_adults = sum(core@data$n_adults)
    enough <- n_adults >= 200
    n_children <- sum(core@data$n_children)
    # enough <- n_children >= 35
  }

  # Create the core
  core <- projected[keep_only,]
  # Create the convex hull
  hull <- gConvexHull(core)
  
  aa <- gArea(hull)
  # Add the buffer to it
  buffer <- gBuffer(hull, width = 0)
  buffer <- SpatialPolygonsDataFrame(
    Sr = buffer,
    data = data.frame(cluster = spatial_dataframe$cluster[1],
                      n_adults,
                      n_children,
                      area = aa),
    match.ID = FALSE
  )
  
  # plot(buffer)
  # points(projected)
  # plot(hull, add = T, col = adjustcolor('red', alpha.f = 0.3))
  
  # Return just those points in the core
  # return_object <- spTransform(core, original_projection)
  return_object <- list(buffer, core)
  return(return_object)
}

pts_list <- buffers_list <- list()
clusters <- sort(unique(x@data$cluster))
for(i in 1:length(clusters)){
  message(i, ' of ', length(clusters))
  this_cluster <- clusters[i]
  this_df <- x[x@data$cluster == this_cluster,]
  this_out <- get_core(this_df)
  this_buffer <- this_out[[1]]
  this_core <- this_out[[2]]
  buffers_list[[i]] <- this_buffer
  pts_list[[i]] <- this_core
}
buffers <- do.call('rbind', buffers_list)
pts <- do.call('rbind', pts_list)

# Loop through each cluster, remove its overlappers, then keep going
buffers_df <- buffers
done <- FALSE
counter <- 0
while(!done){
  counter <- counter + 1
  this_buffer <- buffers_df[counter,]  
  other_buffers <- buffers_df[!(1:nrow(buffers_df)) %in% counter,]
  # Identify overlappers
  overlappers <- gIntersects(spgeom1 = this_buffer,
                             spgeom2 = other_buffers, byid = T)
  overlappers <- overlappers[,1]
  message('Going to remove ',
          length(which(overlappers)),
          ' overlapping clusters')
  # plot(buffers)
  # plot(this_buffer, col = 'red', add = TRUE)
  # plot(other_buffers[overlappers,],
  #      col = adjustcolor('blue', alpha.f = 0.3),
  #      add = T)
  # Remove the overlappers
  non_overlappers <- other_buffers[!overlappers,]
  buffers_df <- rbind(this_buffer, non_overlappers)
  done <- counter >= nrow(buffers_df)
  # print(nrow(buffers_df))
  # Sys.sleep(3)
}
# remove points which did not make it through the overlap too
pts <- pts[pts@data$cluster %in% buffers_df@data$cluster,]

plot(buffers_df)
points(pts, pch = '.')

# Remove those with < 35 children
buffers_df@data$remove <- buffers_df@data$n_children < 35
plot(buffers_df, col = ifelse(buffers_df@data$remove, 'red', 'blue'))
table(buffers_df@data$remove)
buffers_df <- buffers_df[!buffers_df@data$remove,]
pts <- pts[pts@data$cluster %in% buffers_df@data$cluster,]

plot(buffers_df)
points(pts, pch = '.')


# randomly sample 147
keep <- sample(1:nrow(buffers_df), 147)
polys <- buffers_df[keep,]
pts <- pts[pts@data$cluster %in% buffers_df@data$cluster,]

plot(buffers_df)
points(pts, pch = '.')


# Assign
assignment_vector <- rep(1:3, each = 49)
assignment_vector <- sample(assignment_vector, length(assignment_vector), replace = FALSE)
polys@data$assignment_group <- assignment_vector

palette <- c('green', 'blue', 'red')
cols <- palette[polys@data$assignment_group]

plot(polys, col = cols, border = NA)

# sanity test
pts@data %>%
  group_by(cluster) %>%
  summarise(bigs = sum(n_adults),
            kids = sum(n_children))
points(pts, pch = '.')

# Loop through each cluster, moving inward form the boundary, to try to get the area with 35 children
pts@data$id <- 1:nrow(pts)
outer_poly_list <- inner_poly_list <- outer_pts_list <- inner_pts_list <- list()
clusters <- sort(unique(polys@data$cluster))
for(i in 1:length(clusters)){
  message(i, ' of ', length(clusters))
  this_cluster <- clusters[i]
  this_poly <- polys[polys@data$cluster == this_cluster,]
  these_pts <- pts[pts@data$cluster == this_cluster,]
  inner_buffer_size <- 0
  n_children <- sum(these_pts@data$n_children)
  # as long as there are enough children, try going inwards
  enough <- n_children >= 35
  while(enough){
    paste0('---', n_children, ' is enough. Going to grow buffer from ', inner_buffer_size, ' to ', inner_buffer_size-10)
    inner_buffer_size <- inner_buffer_size-10
    # Make the buffer
    buff <- gBuffer(this_poly, width = inner_buffer_size)
    # plot(this_poly)
    # plot(buff, lty = 2, add = T)
    # Get the points within these buffers
    o <- over(these_pts, polygons(buff))
    buff_pts <- these_pts[!is.na(o),]
    # points(these_pts)
    # points(buff_pts, col = 'red')
    # Get number of children remaining
    n_children <- sum(buff_pts@data$n_children)
    enough <- n_children >= 35
  }
  # Having reached the "not enough" point, add 10 meters back to get to the minimum enough
  inner_buffer_size <- inner_buffer_size + 10
  # Make the buffer
  buff <- gBuffer(this_poly, width = inner_buffer_size)
  buff <- SpatialPolygonsDataFrame(Sr = buff, data = this_poly@data %>% mutate(inner_buffer_size = inner_buffer_size),
                                   match.ID = FALSE)
  plot(this_poly)
  title(main = paste0('Cluster ', i, ', inner buffer meters: ', inner_buffer_size))
  plot(buff, lty = 2, add = T)
  # Get the points within these buffers
  o <- over(these_pts, polygons(buff))
  buff_pts <- these_pts[!is.na(o),]
  points(these_pts)
  points(buff_pts, col = 'red')
  # Get number of children remaining
  n_children <- sum(buff_pts@data$n_children)
  # Save the final stuff
  
  outer_poly_list[[i]] <- this_poly 
  inner_poly_list[[i]] <- buff
  outer_pts_list[[i]] <- these_pts
  inner_pts_list[[i]] <- buff_pts
  # Sys.sleep(2)
}
outer_polys <- do.call('rbind', outer_poly_list)
inner_polys <- do.call('rbind', inner_poly_list)
outer_pts <- do.call('rbind', outer_pts_list)
inner_pts <- do.call('rbind', inner_pts_list)
# Remove those outer pts which are part of the inner pts
outer_pts <- outer_pts[!outer_pts@data$id %in% inner_pts@data$id,]

outer_pts_ll <- spTransform(outer_pts, proj4string(bohemia::mop2))
outer_polys_ll <- spTransform(outer_polys, proj4string(bohemia::mop2))

inner_pts_ll <- spTransform(inner_pts, proj4string(bohemia::mop2))
inner_polys_ll <- spTransform(inner_polys, proj4string(bohemia::mop2))

leaflet() %>%
  addTiles() %>%
  addPolylines(data = outer_polys_ll, weight = 1, col = 'black', opacity = 1) %>%
    addPolylines(data = inner_polys_ll, weight = 1, col = 'red', opacity = 1) %>%
    addCircleMarkers(data = outer_pts_ll, col = 'black', radius = 0.3, opacity = 0.7) %>%
    addCircleMarkers(data = inner_pts_ll, col = 'red', radius = 0.3, opacity = 0.7)

```

# Most successful method so far

```{r}
# go through each individual household, defining cores along the way
households <- df_sp[df_sp@data$code %in% df$code[df$country == 'Mozambique'],]# %>% filter(country == 'Mozambique')
households_projected <- spTransform(households, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
# Get distances between all households
all_distances <- gDistance(households_projected, byid = T)
```


```{r}
carlos_list <- list()
buffer_distances <- seq(100, 2000, 100)
for(bf in 1:length(buffer_distances)){
  buffer_distance  <- buffer_distances[bf]
  
# go through each individual household, defining cores along the way
households <- df_sp[df_sp@data$code %in% df$code[df$country == 'Mozambique'],]# %>% filter(country == 'Mozambique')
households_projected <- spTransform(households, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
households_projected@data$id <- 1:nrow(households_projected)
households_projected$status <- 'available'
households_projected$cluster <- households_projected$cc <- households_projected$assignment_group <- NA

households_projected@data$distance_id <- 1:nrow(households_projected)


# Define a function for creating a core given a point and a set of eligible households

create_core <- function(pt, eligibles, n_clusters = 1){
  # Get distance from pt to eligibles
  distances <- spDists(pt, eligibles)
  distances <- distances[1,]
  
  keep <- order(distances)
  enough <- FALSE
  counter <- 0
  cc_vec <- cluster_number_vec <- c()
  cluster_number <- 1
  while(!enough){
    # message('---working on cluster ', cluster_number)
    counter <- counter + 1

    keep_only <- keep[1:counter]
    core <- eligibles[keep_only,]
    n_children <- sum(core@data$n_children)
    cc_vec[counter] <- n_children
    cluster_number_vec[counter] <- cluster_number
    xdf <- tibble(cc = cc_vec,
                  cluster = cluster_number_vec) %>%
      mutate(n_c = cc - dplyr::lag(cc, 1)) %>%
      mutate(n_c = ifelse(is.na(n_c), cc, n_c))
    xdf <- xdf %>% filter(cluster == cluster_number)
    # see if we've just passed the threshold for this cluster
    just_passed <- FALSE
    if(nrow(xdf) > 1){
        just_passed <- sum(xdf$n_c) >=35
        if(just_passed){
          cluster_number <- cluster_number + 1
        }
    }
    enough <- cluster_number > n_clusters #n_children >= (35*n_clusters)
  }
  cc_out <- cluster_number_vec
  core@data$cc <- cc_out
  message('---Successfully created a core area of ', n_children)
  return(core)
}


# Define a random starting point
set.seed(1)
library(rangemap)
done <- FALSE
cluster_counter <- 0
buffers_list <- cores_list <- cores_poly_list <- list()
palette <- rainbow(3)

# Create an assignment vector
assignment_vector <- c(rep(1, 49), rep(2, 49), rep(3, 49))
assignment_vector <- sample(assignment_vector, length(assignment_vector))
# Add to it in case we have more than 3*48 clusters
part2 <- sample(1:3, size = 1000000 - length(assignment_vector), replace = TRUE)
assignment_vector <- c(assignment_vector, part2) # this is now unnecessarily long, but at least has perfect uniform distribution for the first 144 elements, which is needed

# Based on assignment vector, get a vector of grouped assignments
assignment_groups <- c(1)
counter <- 1
for(i in 2:length(assignment_vector)){
  if(!assignment_vector[i] == assignment_vector[i-1]){
    counter <- counter + 1
  }
  assignment_groups[i] <- counter
}
unique_assignment_groups <- sort(unique(assignment_groups))
ag_df <- tibble(assignment = assignment_vector,
                assignment_group = assignment_groups)
ag_counter <- 0
cols <- palette[ag_df$assignment]


while(!done){
  ag_counter <- ag_counter + 1  
  this_assignment <- ag_df$assignment[ag_df$assignment_group == ag_counter][1]

  # Get the n rows for the assignment group
  nr <- ag_df %>% filter(assignment_group == ag_counter) %>% nrow()
  # Get number of children
  n <- nr * 35
  # cluster_counter <- cluster_counter + 1
  # this_assignment <- assignment_vector[cluster_counter]
  message('Working on assignment group: ', ag_counter, '. ', nr, ' clusters')
  # elbs <- households_projected[households_projected@data$status == 'available',]
  elbs <- households_projected[households_projected@data$status != 'core',]
  eligible_ids <- elbs@data$distance_id
  
  if(ag_counter > 1){
      # Eligibles have to be at least 2km from the edge of the already assigned areas
     # elbs_distances <- gDistance(all_buffers, elbs, byid = T) # get distance from all_buffers
    # We want to get those which are FAR from households already assigned to ANOTHER assignment status
    previous <- households_projected
    previous@data <- left_join(previous@data, ag_df %>% dplyr::distinct(assignment_group, assignment))
    # previous_nas <- previous[is.na(previous@data$assignment),] 
    as_close_to_here_as_possible <- previous_not_nas <- previous[!is.na(previous@data$assignment),]
    previous_not_nas <- previous_not_nas[previous_not_nas@data$assignment != this_assignment,]
    stay_away_from_these <- previous_not_nas
  # stay_away_from_these <- hull_polygon(stay_away_from_these, hull_type = 'concave')#gConvexHull(core)
  #   stay_away_from_these <- SpatialPolygonsDataFrame(
  #   Sr = stay_away_from_these,
  #   data = data.frame(x = 1),
  #   match.ID = FALSE
  # )
    stay_away_from_these_ids <- stay_away_from_these@data$distance_id
    
    # Keep ONLY households which are sufficiently far from the stay-away households
    these_distances <- all_distances[eligible_ids, stay_away_from_these_ids]
    elbs_distances <- apply(these_distances, 1, min)
    keep_elbs <- elbs_distances >= (buffer_distance*2) # multiply by 2, since the distance is not including their buffer
    elbs <- elbs[keep_elbs,]

    # Now we have only eligible points. But we want to start the next one as close as possible to
    # the already assigned areas. THIS CAUSES ISSUES. COMMENTING OUT
    # eligible_ids <- elbs@data$distance_id
    # as_close_to_here_as_possible_ids <- as_close_to_here_as_possible@data$distance_id
    # these_distances <- all_distances[eligible_ids, as_close_to_here_as_possible_ids]
    # elbs_distances <- apply(these_distances, 1, min)
    # random_index <- which.min(elbs_distances)[1]
    random_index <- sample(1:nrow(elbs), 1)
    
  } else {
    random_index <- sample(1:nrow(elbs), 1)
  }

  this_hh <- elbs[random_index,]
  # Create core
  core <- create_core(pt = this_hh, eligibles = elbs, n_clusters = nr)
  core@data %>%
    group_by(cc) %>%
    summarise(kids = sum(n_children))
  # Create convex hull
  suppressMessages({
    hull <- hull_polygon(core, hull_type = 'concave')#gConvexHull(core)
    hull <- SpatialPolygonsDataFrame(
    Sr = hull,
    data = data.frame(assignment_group = ag_counter,
                      assignment = this_assignment),
    match.ID = FALSE
  )
  })
  # # Create buffer 
  # buffer <- gBuffer(core, width = buffer_distance)
  # buffer <- SpatialPolygonsDataFrame(
  #   Sr = buffer,
  #   data = data.frame(assignment_group = ag_counter,
  #                     assignment = this_assignment),
  #   match.ID = FALSE
  # )
  # # Identify the households in the buffer
  # hh_in_buffer_index <- over(households_projected, polygons(buffer))
  # hh_in_buffer_index <- which(!is.na(hh_in_buffer_index))
  # hh_in_buffer <- households_projected[hh_in_buffer_index,]
  # # Get the ids of those in the buffer
  # ids_in_buffer <- hh_in_buffer@data$id
  # Get the ids of those in core
  ids_in_core <- core@data$id
  # ids_in_buffer <- ids_in_buffer[!ids_in_buffer %in% ids_in_core]
  message('------', length(ids_in_core), ' households in core.')
  message('------', sum(core@data$n_children), ' children in core.')
  # message('------', length(ids_in_buffer), ' households in buffer')
  # Write to the master dataframe
  # households_projected@data$status[households_projected@data$id %in% ids_in_buffer] <- 'buffer'
  # households_projected@data$status[households_projected@data$id %in% ids_in_core] <- 'core'
  # households_projected@data$assignment_group[households_projected@data$id %in% ids_in_buffer] <- ag_counter
  # households_projected@data$assignment_group[households_projected@data$id %in% ids_in_core] <- ag_counter
  core@data$assignment_group <- ag_counter
  core@data$status <- 'core'
  # Get the cc number
  non_core <- households_projected[!households_projected@data$id %in% ids_in_core,]
  households_projected <- rbind(core, non_core)
  # # Save polygons
  # buffers_list[[ag_counter]] <- buffer
  # cores_list[[ag_counter]] <- core
  cores_poly_list[[ag_counter]] <- hull
  # 
  # 
  # # Create an evolving map of buffers
  # all_buffers <- do.call('rbind', buffers_list)
  # all_buffers <- spTransform(all_buffers, proj4string(households_projected))
  all_cores <- do.call('rbind', cores_poly_list)
  all_cores <- spTransform(all_cores, proj4string(households_projected))

  sub_ag_df <- ag_df %>% filter(assignment_group <= ag_counter)
  already_assigned <- households_projected[households_projected@data$status == 'core',]
  already_assigned@data <- left_join(already_assigned@data, ag_df %>% dplyr::distinct(assignment, assignment_group))
  # plot(households_projected, pch = '.', cex = 0.5,
  #      col = adjustcolor('black', alpha.f = 0.3))
  # plot(all_cores, add = T,
  #      col = adjustcolor(cols[1:ag_counter], alpha.f = 0.3))
  plot(already_assigned, pch = '.',
         col = cols[already_assigned@data$assignment])
  plot(all_cores, add = T)
  

  title(main = paste0(ag_counter, ' assignment groups finished.\nBuffer distance: ', buffer_distance),
        sub = paste0(nrow(sub_ag_df), ' clusters done.'))
  tt <- households_projected@data %>%
    group_by(assignment_group, cc) %>%
    summarise(kids = sum(n_children))
  print(ungroup(tt))
  # print(table(households_projected@data$assignment_group[households_projected@data$status == 'core']))
  # Sys.sleep(0.35)
  # Check to see if done
  cluster_counter <- nrow(sub_ag_df)
  done <- cluster_counter >= 147

}

# Having assigned, now get summary data
households_projected@data <- households_projected@data %>% left_join(ag_df %>% dplyr::distinct(assignment, assignment_group))
sub_data <- households_projected[households_projected@data$status == 'core',]
plot(sub_data,
     col = cols[sub_data@data$assignment])
ags <- sub_data@data %>%
  group_by(assignment_group) %>%
  tally %>%
  filter(n > 1) %>%
  .$assignment_group
ags <- sort(unique(sub_data@data$assignment_group))
ag_list <- list()
counter <- 0
for(i in 1:length(ags)){
  message(i)
  this_ag <- ags[i]
  this_ag_data <- sub_data[sub_data@data$assignment_group == this_ag,]
  if(nrow(this_ag_data) > 2){
    counter <- counter + 1
  this_hull <- hull_polygon(this_ag_data, hull_type = 'concave')
  hull <- SpatialPolygonsDataFrame(
    Sr = this_hull,
    data = data.frame(assignment_group = this_ag,
                      assignment = this_ag_data@data$assignment[1]),
    match.ID = FALSE)
  ag_list[[counter]] <- hull
  }
}
ags <- do.call('rbind', ag_list)

plot(ags,
     col = cols[ags@data$assignment])

# Get buffers
gbufs <- gBuffer(ags, width = buffer_distance)
plot(gbufs, add = T) # this is visually nice, but a bit misleading, since it sometimes shows shapes in areas which aren't really there

# Buffer points
core_points <- households_projected[households_projected@data$status == 'core',]
plot(core_points, pch = '.', col = cols[core_points@data$assignment])

# The assignment / assignment group variables tell us which core areas get what treatment
# They should also be correct (at least in terms of assignment) for the buffer areas too

# Get the correct cluster number for each core
households_projected@data$cluster <- as.numeric(factor(paste0(households_projected@data$assignment_group, '-', households_projected@data$cc)))
households_projected@data$cluster <- ifelse(households_projected@data$cluster > 147, NA, households_projected@data$cluster)
households_projected@data %>%
  group_by(cluster) %>%
  summarise(kids = sum(n_children)) %>%
  arrange((kids))

households_projected@data %>%
  group_by(assignment_group, cc) %>%
  summarise(kids = sum(n_children)) %>%
  arrange((kids))


# Need to get the buffer status of all households NOT in core
# will do so by getting the status of the nearest one
households_core <- households_projected[households_projected@data$status == 'core',]
core_ids <- households_core@data$distance_id
households_non_core <- households_projected[households_projected@data$status != 'core',]
non_core_ids <- households_non_core@data$distance_id
distance_to_cores <- 
  all_distances[non_core_ids, core_ids]
min_distance <- apply(distance_to_cores, 1, min)
nearest_one <- apply(distance_to_cores, 1, which.min)
households_non_core@data$assignment <- households_core@data$assignment[nearest_one]
households_non_core@data$status <- ifelse(as.numeric(min_distance) <= buffer_distance, 'buffer', 'non-study')
households_non_core@data$assignment <- ifelse(households_non_core@data$status == 'non-study',NA, households_non_core@data$assignment)
table(households_non_core@data$assignment, households_non_core@data$status)
# Join back to households main
households_projected <-
  rbind(households_core,
        households_non_core)

# Downsample to just clusters 1:147
down_sampled <- households_projected@data %>%
  filter(!is.na(assignment))
oos <- households_projected@data %>%
  filter(is.na(assignment) | is.na(cluster))
table(households_projected@data$status, households_projected@data$assignment)

# Group by assignment and get some values
carlos <- down_sampled %>%
  group_by(assignment) %>%
  summarise(hh = n(),
            n_cluster = length(unique(cluster[status == 'core'])),
            hh_core = length(which(status == 'core')),
            hh_buffer = length(which(status == 'buffer')),
            people = sum(n_people),
            people_core = sum(n_people[status == 'core']),
            people_buffer = sum(n_people[status == 'buffer']),
            kids = sum(n_children),
            kids_core = sum(n_children[status == 'core']),
            kids_buffer = sum(n_children[status == 'buffer'])) %>%
  mutate(adults = people - kids,
         adults_core = people_core - kids_core,
         adults_buffer = people_buffer - kids_buffer) %>%
  dplyr::select(-people, -people_core, -people_buffer, -kids) %>%
  mutate(buffer_meters = buffer_distance)
message('Out of study: ', nrow(oos), ' households with ', sum(oos$n_people), ' people')
message('Number of adults in core+buffer areas: ', sum(carlos$adults_buffer + carlos$adults_core), ' (should be <=30k)')
save(households_projected, carlos, file = paste0(buffer_distance, '.RData'))
carlos_list[[bf]] <- carlos
}
carlos <- bind_rows(carlos_list) %>%
  mutate(treatable_adults = adults_buffer + adults_core)

pd <- carlos %>%
  group_by(buffer_meters) %>%
  summarise(treatable_adults = sum(treatable_adults))
ggplot(data = pd,
       aes(x = buffer_meters,
           y = treatable_adults)) +
  geom_point() +
  geom_smooth() +
  labs(title = 'Treatable adults (core + buffer)')


# Make a map
in_core <- households_projected[households_projected@data$status == 'core',]
in_core <- spTransform(in_core, proj4string(bohemia::mop2))

icons <- awesomeIcons(
  # icon = 'ios-close',
  # iconColor = 'black',
  library = 'ion',
  markerColor = cols[in_core@data$assignment]
)

in_buffer <- households_projected[households_projected@data$status == 'buffer',]
in_buffer <- spTransform(in_buffer, proj4string(bohemia::mop2))
non_study <- households_projected[households_projected@data$status == 'non-study',]
non_study <- spTransform(non_study, proj4string(bohemia::mop2))
greenLeafIcon <- makeIcon(
  iconUrl = "http://leafletjs.com/examples/custom-icons/leaf-green.png",
  iconWidth = 5, iconHeight = 12,
  iconAnchorX = 2, iconAnchorY = 12#,
  # shadowUrl = "http://leafletjs.com/examples/custom-icons/leaf-shadow.png",
  # shadowWidth = 50, shadowHeight = 64,
  # shadowAnchorX = 4, shadowAnchorY = 62
)
l = leaflet() %>%
  addTiles() %>%
  # addAwesomeMarkers(data = in_core, icon=icons)

  addCircleMarkers(data = in_core, fillColor = cols[in_core@data$assignment],
                   weight = 2, radius = 6,
                   color =  cols[in_core@data$assignment]) %>%
    # addMarkers(data = in_buffer, icon = greenLeafIcon) %>%
  addCircleMarkers(data = in_buffer, col = 'yellow',
                   radius = 4,
             weight = 2, fillColor = cols[in_buffer@data$assignment]) %>%
  addCircleMarkers(data = non_study, col = 'black',
                   weight = 0, radius = 2) 
htmlwidgets::saveWidget(widget = l, file = '~/Desktop/vis.html', selfcontained = F)
```


## K means

```{r}
x <- df %>% filter(country == 'Mozambique')
# ggplot(data = x,
#        aes(x = lng,
#            y = lat,
#            color = n_children>=35)) +
#   geom_point()


# # Create a dataframe of only children
# child_list <- list()
# counter <- 0
# for(i in 1:nrow(df_full)){
#   message(i, ' of ', nrow(df_full))
#   this_hh <- df_full[i,]
#   n_children <- this_hh$n_children
#   if(n_children > 0){
#     counter <- counter +1
#     out_df <- tibble(number = 1:n_children,
#                      code = this_hh$code,
#                      instance_id = this_hh$instance_id,
#                      location = this_hh$location)
#     child_list[[counter]] <- out_df
#   }
# }
# children <- bind_rows(child_list)
# x <- children %>%
#   left_join(df %>% dplyr::select(code,
#                                  country)) %>%
#   filter(country == 'Mozambique')
# locs <- extract_ll(x$location)
# x$lng <- locs$lng; x$lat <- locs$lat

k <- kmeans(x = x[,c('lng', 'lat')],
            centers = 150)

k_centroids <- k$centers
plot(bohemia::mop2)
points(k_centroids)

x$cluster <- k$cluster
# x$cluster <- as.numeric(factor(x$code))
cols <- rainbow(max(x$cluster))
cols_vec <- adjustcolor(cols[x$cluster], alpha.f = 0.3)
plot(x$lng, x$lat, col = cols_vec, pch = '.', cex = 1)

ggplot(data = x,
       aes(x = lng,
           y = lat,
           col = factor(cluster))) +
  geom_point(alpha = 0.8, size = 0.8) +
  theme(legend.position = 'none')

# leaflet() %>%
#   addProviderTiles(providers$Esri.WorldImagery) %>%
#   addCircleMarkers(data = x,
#                    weight = 3,
#                    opacity = 0,
#                    fillOpacity = 0.7,
#                    fillColor = cols_vec)

agg <- x %>% 
  group_by(cluster) %>%
  summarise(n = n())


```


## Simple method (outward in)

```{r}
# Hamlet method
pd <- df_sp[df_sp@data$country == 'Mozambique',]
coords <- coordinates(pd)
pd@data$lng <- coords[,1]
pd@data$lat <- coords[,2]
pd$id <- pd$code

# # Children method
# pd <- x
# pd$id <- pd$cluster
# pd$x <- pd$lng; pd$y <- pd$lat
# coordinates(pd) <- ~x+y
# proj4string(pd) <- proj4string(bohemia::mop2)


v <- voronoi(shp = pd, poly = bohemia::mop2)

# Create an assignment vector
assignment_vector <- c(rep(1, 49), rep(2, 49), rep(3, 49))
assignment_vector <- sample(assignment_vector, length(assignment_vector))
# Add to it in case we have more than 3*48 clusters
part2 <- sample(1:3, size = 1000000 - length(assignment_vector), replace = TRUE)
assignment_vector <- c(assignment_vector, part2) # this is now unnecessarily long, but at least has perfect uniform distribution for the first 144 elements, which is needed
v@data$assignment_group <- assignment_vector[1:nrow(v)]

# Project
vp <- spTransform(v, CRS("+proj=utm +zone=36 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))

# Get inner buffer of 1 km
vb <- gBuffer(vp, byid = T, width = -1000)

# Cast back to lng/lat
vbll <- spTransform(vb, proj4string(bohemia::mopeia2))


# Plot
plot(vbll)

# Get how many people are in each area
hh <- x#df_sp[df_sp@data$country == 'Mozambique',]
coordinates(hh) <- ~lng+lat
proj4string(hh) <- proj4string(bohemia::mop2)
coords <- coordinates(hh)
hh@data$lng <- coords[,1]
hh@data$lat <- coords[,2]
hh$id <- hh$code
overx <- over(hh, polygons(vbll))

keep <- hh[!is.na(overx),]
points(keep, col = 'red', pch = '.')
nrow(keep)
keep@data %>%
  group_by(cluster) %>%
  tally
```

